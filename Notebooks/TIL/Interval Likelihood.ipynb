{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:16.974084Z",
     "start_time": "2024-09-19T08:57:16.530905Z"
    }
   },
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "import struct\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, rv_histogram\n",
    "from tqdm.auto import tqdm\n",
    "from pympler import asizeof\n",
    "\n",
    "pd.set_option('display.float_format', str)\n",
    "\n",
    "######### SELECT THE DATASET #########\n",
    "# DATASET = 'Syncan'\n",
    "DATASET = 'X-CANIDS'\n",
    "DATASET_DIR = f'../../Dataset/{DATASET}'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:16.981595Z",
     "start_time": "2024-09-19T08:57:16.975207Z"
    }
   },
   "source": [
    "def str_to_list(data_str: str) -> list:\n",
    "    data_list_str = data_str.split()\n",
    "    data_list = [int(x) for x in data_list_str]\n",
    "    if len(data_list) < 8:  # fill with dummy values (0) to 8 bytes\n",
    "        data_list += [0] * (8 - len(data_list))\n",
    "    return data_list\n",
    "\n",
    "def bytes_to_list(data_bytes: bytes) -> list:\n",
    "    l = len(data_bytes)\n",
    "    decimal_values = struct.unpack(f'{l}B', data_bytes)\n",
    "    return list(decimal_values)\n",
    "\n",
    "def load_arrange_data(file_path, dataset, print_option=True):\n",
    "    if dataset == 'Syncan':\n",
    "        df = pd.read_csv(file_path, delimiter=',')\n",
    "        df['Time'] = round(df['Time'] / 1000, 7)     # milliseconds to seconds\n",
    "        df.rename(columns={'Label': 'Session'}, inplace=True)\n",
    "        df['SessionCat'] = 'Normal'\n",
    "        df.loc[df['Session'] == 1, 'SessionCat'] = 'Attack'\n",
    "        if print_option:\n",
    "            print(f'# rows: {df.shape[0]:,}')\n",
    "            print(df['Session'].value_counts())\n",
    "        return df\n",
    "    elif dataset == 'X-CANIDS':\n",
    "        df = pd.read_parquet(file_path)\n",
    "        # make SessionCat\n",
    "        df['Label'] = 'Normal'\n",
    "        splits = Path(file_path).stem.split('-')\n",
    "        attack_map_dict = {'fabr': 'Fabrication', 'fuzz': 'Fuzzing', 'masq': 'Masquerade', 'repl': 'Replay', 'susp': 'Suspension'}\n",
    "        attack = None\n",
    "        if len(splits) > 1:\n",
    "            attack, aidh = attack_map_dict[splits[1]], splits[2]\n",
    "            df.loc[df['label'] == 1, 'Label'] = attack\n",
    "        # Make Session labels (Note: Attacks in X-CANIDS Dataset were performed without a pause)\n",
    "        df['Session'] = 0\n",
    "        df['SessionCat'] = 'Normal'\n",
    "        msgs = df.loc[df['label'] == 1]\n",
    "        t_start, t_end = 0, 0\n",
    "        if msgs.shape[0] > 0:  # if the dataset includes attack messages\n",
    "            t_start, t_end = msgs.index.min(), msgs.index.max()\n",
    "            df.loc[t_start:t_end, 'Session'] = 1\n",
    "            df.loc[t_start:t_end, 'SessionCat'] = attack\n",
    "            assert df.query('label == 1 and Session == 0').shape[0] == 0   \n",
    "        if attack == 'Suspension':  # it doens't have label=1 rows, so apply a rough approach\n",
    "            assert len(df.loc[(480 < df.index.total_seconds()) & (df.index.total_seconds() <= 1440) & (df['label'] == 1)]) == 0\n",
    "            df.loc[(480 < df.index.total_seconds()) & (df.index.total_seconds() <= 1440), 'Session'] = 1\n",
    "            df.loc[(480 < df.index.total_seconds()) & (df.index.total_seconds() <= 1440), 'SessionCat'] = attack\n",
    "        # Format columns\n",
    "        df.reset_index(inplace=True)\n",
    "        df['Time'] = df['timestamp'].dt.total_seconds()\n",
    "        df['Data'] = df['data'].apply(bytes_to_list)\n",
    "        df.rename(columns={'arbitration_id': 'ID', 'dlc': 'DLC'}, inplace=True)\n",
    "        if print_option:\n",
    "            print(f'# rows: {df.shape[0]:,}')\n",
    "            print(pd.concat([df['Label'].value_counts().rename('Label'), df['SessionCat'].value_counts().rename('SessionCat')], axis=1))\n",
    "        return df[['Session', 'SessionCat', 'Label', 'Time', 'ID', 'DLC', 'Data']]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Define a training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:16.985586Z",
     "start_time": "2024-09-19T08:57:16.982384Z"
    }
   },
   "source": [
    "if DATASET == 'Syncan':\n",
    "    data_files = {\n",
    "        'train': [\n",
    "            f'{DATASET_DIR}/train_train.csv'\n",
    "        ],\n",
    "        'valid': [\n",
    "            f'{DATASET_DIR}/train_valid.csv'\n",
    "        ],\n",
    "        'test': [\n",
    "            f'{DATASET_DIR}/test_normal.csv',\n",
    "            f'{DATASET_DIR}/test_flooding.csv',\n",
    "            f'{DATASET_DIR}/test_plateau.csv',\n",
    "            f'{DATASET_DIR}/test_continuous.csv',\n",
    "            f'{DATASET_DIR}/test_playback.csv',\n",
    "            f'{DATASET_DIR}/test_suppress.csv'\n",
    "        ]\n",
    "    }\n",
    "elif DATASET == 'X-CANIDS':\n",
    "    data_files = {\n",
    "        'train': glob.glob(f'{DATASET_DIR}/raw/dump[1-4].parquet'),\n",
    "        'valid': [f'{DATASET_DIR}/raw/dump5.parquet'],\n",
    "        'test': glob.glob(f'{DATASET_DIR}/raw/dump6-*.parquet')\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": "# Statistical Feature Extraction"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:16.989737Z",
     "start_time": "2024-09-19T08:57:16.987134Z"
    }
   },
   "source": [
    "def time_cut(data: pd.DataFrame):\n",
    "    time_cut = data.loc[data.groupby('ID').cumcount() == 1, 'Time'].max()  # the timestamp that every ID has been occurred at least twice\n",
    "    return time_cut\n",
    "\n",
    "def get_time_intervals(data: pd.DataFrame, ffill: bool, cut: bool):\n",
    "    data = data[['Session', 'Time', 'ID']].copy()\n",
    "    n_rows = data.shape[0]\n",
    "    data['Interval'] = data.groupby('ID')['Time'].diff()\n",
    "    data_itv = pd.concat([data[['Session', 'Time']], data.pivot(columns='ID', values='Interval')], axis=1)\n",
    "    if ffill:\n",
    "        data_itv.ffill(inplace=True)\n",
    "    if cut:\n",
    "        t_cut = time_cut(data)\n",
    "        data_itv = data_itv.loc[data_itv['Time'] >= t_cut]\n",
    "        # print(f'Data has been truncated to remove NaN ({n_rows - data_itv.shape[0]:,} rows removed)')\n",
    "    if ffill and cut:\n",
    "        assert data_itv.isna().sum().sum() == 0\n",
    "    return data_itv"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:36.837827Z",
     "start_time": "2024-09-19T08:57:16.990257Z"
    }
   },
   "source": [
    "ids_union = set()\n",
    "ids_inter = set()\n",
    "itv_dfs = list()\n",
    "\n",
    "total_rows = 0\n",
    "for data_file in data_files['train']:\n",
    "    print(f'{data_file}')\n",
    "    df_data = load_arrange_data(data_file, dataset=DATASET)\n",
    "    total_rows += df_data.shape[0]\n",
    "    unique_ids = set(df_data['ID'].unique())\n",
    "    print(f'# unique CAN IDs = {len(unique_ids)}')\n",
    "    ids_union |= unique_ids\n",
    "    if not ids_inter:\n",
    "        ids_inter = unique_ids.copy()\n",
    "    else:\n",
    "        ids_inter &= unique_ids\n",
    "    df_data_itv = get_time_intervals(df_data, ffill=False, cut=True)\n",
    "    itv_dfs.append(df_data_itv)\n",
    "\n",
    "df_itv_concat = pd.concat(itv_dfs, axis=0, ignore_index=True)\n",
    "print('\\nAll ID-specific time intervals in the train dataset are concatenated.')\n",
    "print(df_itv_concat.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Dataset/X-CANIDS/raw/dump4.parquet\n",
      "# rows: 4,761,327\n",
      "          Label  SessionCat\n",
      "Normal  4761327     4761327\n",
      "# unique CAN IDs = 64\n",
      "../../Dataset/X-CANIDS/raw/dump1.parquet\n",
      "# rows: 3,123,785\n",
      "          Label  SessionCat\n",
      "Normal  3123785     3123785\n",
      "# unique CAN IDs = 62\n",
      "../../Dataset/X-CANIDS/raw/dump3.parquet\n",
      "# rows: 3,233,753\n",
      "          Label  SessionCat\n",
      "Normal  3233753     3233753\n",
      "# unique CAN IDs = 62\n",
      "../../Dataset/X-CANIDS/raw/dump2.parquet\n",
      "# rows: 4,134,502\n",
      "          Label  SessionCat\n",
      "Normal  4134502     4134502\n",
      "# unique CAN IDs = 64\n",
      "\n",
      "All ID-specific time intervals in the train dataset are concatenated.\n",
      "(15174570, 66)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:36.840422Z",
     "start_time": "2024-09-19T08:57:36.838492Z"
    }
   },
   "source": [
    "print(f'\\nCAN IDs in every dataset ({len(ids_inter)}): {sorted(list(ids_inter))}')\n",
    "print(f'\\nCAN IDs only in a specific dataset ({len(ids_union - ids_inter)}): {sorted(list(ids_union - ids_inter))}')\n",
    "target_ids = sorted(list(ids_inter))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CAN IDs in every dataset (62): [66, 67, 68, 127, 128, 129, 273, 274, 275, 339, 354, 356, 399, 512, 544, 593, 608, 688, 790, 809, 897, 899, 902, 903, 1040, 1078, 1151, 1168, 1170, 1265, 1280, 1282, 1287, 1292, 1312, 1314, 1322, 1331, 1332, 1333, 1345, 1348, 1349, 1351, 1353, 1356, 1363, 1365, 1366, 1367, 1369, 1407, 1415, 1419, 1427, 1440, 1456, 1460, 1470, 1472, 1491, 1530]\n",
      "\n",
      "CAN IDs only in a specific dataset (2): [2016, 2024]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:44.457313Z",
     "start_time": "2024-09-19T08:57:36.841131Z"
    }
   },
   "source": [
    "# The mean and standard deviation of time intervals (ID-specific)\n",
    "ignore_cols = ['Session', 'Time']\n",
    "df_itv_gauss = pd.concat(\n",
    "    [df_itv_concat.drop(columns=ignore_cols).mean().rename('mean'), \n",
    "     df_itv_concat.drop(columns=ignore_cols).std().rename('std')], \n",
    "    axis=1\n",
    ")\n",
    "display(df_itv_gauss)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     mean                    std\n",
       "66     0.9954650628489622    0.04429268355672397\n",
       "67     0.9976073837876608 0.00026340187106257463\n",
       "68     0.9490001651426233     0.1966017799689265\n",
       "127     0.999511213659238 0.00012761940997246284\n",
       "128  0.009999059567974335  0.0003118041254577753\n",
       "...                   ...                    ...\n",
       "1472   0.9995107404744777  0.0007597910838317148\n",
       "1491   0.9996947733218344  0.0008563397188535947\n",
       "1530   1.0009190113701798  0.0010015640158069577\n",
       "2016            11.029508      9.050514872829723\n",
       "2024    5.511082999999999      9.164676961945112\n",
       "\n",
       "[64 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.9954650628489622</td>\n",
       "      <td>0.04429268355672397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.9976073837876608</td>\n",
       "      <td>0.00026340187106257463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.9490001651426233</td>\n",
       "      <td>0.1966017799689265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.999511213659238</td>\n",
       "      <td>0.00012761940997246284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.009999059567974335</td>\n",
       "      <td>0.0003118041254577753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>0.9995107404744777</td>\n",
       "      <td>0.0007597910838317148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>0.9996947733218344</td>\n",
       "      <td>0.0008563397188535947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1.0009190113701798</td>\n",
       "      <td>0.0010015640158069577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>11.029508</td>\n",
       "      <td>9.050514872829723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>5.511082999999999</td>\n",
       "      <td>9.164676961945112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:44.722871Z",
     "start_time": "2024-09-19T08:57:44.458101Z"
    }
   },
   "source": [
    "del df_itv_concat\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Normalized Likelihood Transformation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:44.726389Z",
     "start_time": "2024-09-19T08:57:44.723492Z"
    }
   },
   "source": [
    "# if gap <= mean, use interval values, and if gap > mean, use gap values\n",
    "def interval_with_gap_condition(data: pd.DataFrame, ids: list): # gauss: pd.DataFrame):\n",
    "    data = data[['Session', 'SessionCat', 'Time', 'ID']].copy()\n",
    "    n_rows = data.shape[0]\n",
    "    t_cut = time_cut(data)\n",
    "    data['Interval'] = data.groupby('ID')['Time'].diff()\n",
    "    data = pd.concat([data[['Session', 'SessionCat', 'Time']], data.pivot(columns='ID', values=['Time', 'Interval'])], axis=1)\n",
    "    ft_dict = {\n",
    "        'Session': data['Session'].to_list(),\n",
    "        'SessionCat': data['SessionCat'].to_list(),\n",
    "        'Time': data['Time'].to_list()\n",
    "    }\n",
    "    for id in ids:\n",
    "        data[('Gap', id)] = data['Time'] - data[('Time', id)].ffill()\n",
    "        data[('Interval', id)] = data[('Interval', id)].ffill()\n",
    "        data[('Gap', id)] = data[[('Interval', id), ('Gap', id)]].max(axis=1)\n",
    "        ft_dict[id] = data[('Gap', id)]\n",
    "    ft_df = pd.DataFrame.from_dict(ft_dict)\n",
    "    ft_df = ft_df.loc[ft_df['Time'] >= t_cut]\n",
    "    return ft_df"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:57:44.744402Z",
     "start_time": "2024-09-19T08:57:44.728081Z"
    }
   },
   "source": [
    "# Get normal distribution classes\n",
    "norm_dist = {'itv': {}}\n",
    "for id in target_ids:\n",
    "    itv_mean = df_itv_gauss.loc[id, 'mean']\n",
    "    itv_std = df_itv_gauss.loc[id, 'std']\n",
    "    if itv_std == 0:    # Some IDs have constant counts at all times, which means std = 0\n",
    "        print('itv', id, itv_mean, itv_std)\n",
    "        norm_dist['itv'][id] = norm(itv_mean, itv_mean * 0.001)   # Set std to a sufficiently small value\n",
    "    else:\n",
    "        norm_dist['itv'][id] = norm(itv_mean, itv_std)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:59:24.316287Z",
     "start_time": "2024-09-19T08:57:44.745034Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Get the maximum value of likelihoods (of the training set)\n",
    "df_itv_likelihoods = list()\n",
    "for data_file in tqdm(data_files['train']):\n",
    "    df = load_arrange_data(data_file, dataset=DATASET, print_option=False)\n",
    "    df_itv = interval_with_gap_condition(df, ids=target_ids) # gauss=df_gauss)\n",
    "    itv_likelihood = dict()\n",
    "    for id in target_ids:\n",
    "        itv_likelihood[id] = norm_dist['itv'][id].logpdf(df_itv[id])\n",
    "    df_itv_likelihoods.append(pd.DataFrame.from_dict(itv_likelihood))\n",
    "\n",
    "max_range = {'itv': [0, 0]}  # [min, max]\n",
    "for df in df_itv_likelihoods: \n",
    "    current_max = df.sum(axis=1).max()\n",
    "    current_min = df.sum(axis=1).min()\n",
    "    if max_range['itv'][0] > current_min:\n",
    "        max_range['itv'][0] = current_min\n",
    "    if max_range['itv'][1] < current_max:\n",
    "        max_range['itv'][1] = current_max\n",
    "print(f'Max range (row-wise): {max_range}')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b8cf81d662f42f589c206b3da080fbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max range (row-wise): {'itv': [-221136.84894687944, 392.66707133555036]}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T08:59:24.544732Z",
     "start_time": "2024-09-19T08:59:24.317079Z"
    }
   },
   "source": [
    "del df_itv_likelihoods\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": "## Calculate z-values and Save"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T08:59:24.548447Z",
     "start_time": "2024-09-19T08:59:24.545411Z"
    }
   },
   "source": [
    "def z_extraction(data_itv: pd.DataFrame, ids: list, norm_dict: dict, likelihood_range: dict):\n",
    "    l_itv_dict = dict()\n",
    "    for id in ids:\n",
    "        l_itv_dict[id] = norm_dict['itv'][id].logpdf(data_itv[id])\n",
    "    l_itv_df = pd.DataFrame.from_dict(l_itv_dict)\n",
    "    l_df = data_itv[['Session', 'SessionCat', 'Time']].copy()\n",
    "    l_df['z_itv'] = ((l_itv_df.sum(axis=1) - likelihood_range['itv'][0]) / (likelihood_range['itv'][1] - likelihood_range['itv'][0])).values\n",
    "    return l_df\n",
    "\n",
    "def get_save_path(original_path: str, dataset: str):\n",
    "    if dataset == 'X-CANIDS':\n",
    "        new_path = f'{Path(original_path).parents[1]}/z/{Path(original_path).stem}.parquet'\n",
    "    elif dataset == 'Syncan':\n",
    "        new_path = f'{Path(original_path).parent}/z/z_{Path(original_path).stem.split(\"_\")[-1]}.parquet'\n",
    "    return new_path"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T10:12:12.222868Z",
     "start_time": "2024-09-19T08:59:24.549236Z"
    }
   },
   "source": [
    "# todo: 기존 z 파일과 차이 존재. 각 공격 후 1초마다 session이 1이 아니라 0으로 기록되고 있음 -> insertion 공격 탐지 성능에 변화가 생길 수 있음 -> 결과적으로 CANet label을 사용해서 무관할 것으로 보임\n",
    "import time\n",
    "\n",
    "for step, file_list in data_files.items():\n",
    "    for data_file in tqdm(file_list, desc=f'Processing {step} datasets'):\n",
    "        # Extract z features\n",
    "        df_itv = load_arrange_data(data_file, dataset=DATASET, print_option=False)\n",
    "        start_time = time.process_time()\n",
    "        df_itv = interval_with_gap_condition(df_itv, ids=target_ids)\n",
    "        df_z = z_extraction(df_itv, ids=target_ids, norm_dict=norm_dist, likelihood_range=max_range)\n",
    "        end_time = time.process_time()\n",
    "        assert df_z.query('Session == 1 and SessionCat == \"Normal\"').shape[0] == 0\n",
    "        assert df_z.query('Session == 0 and SessionCat != \"Normal\"').shape[0] == 0\n",
    "\n",
    "        # Save as a parquet file\n",
    "        str_cols = [str(c) for c in df_z.columns]\n",
    "        df_z.columns = str_cols\n",
    "        save_path = get_save_path(data_file, dataset=DATASET)\n",
    "        df_z.to_parquet(save_path)\n",
    "        # print(df_z.Session.value_counts())\n",
    "        print(f'{save_path} is saved.')\n",
    "        \n",
    "# Measure inference speed\n",
    "process_time = end_time - start_time\n",
    "inference_speed = len(df_itv) / process_time\n",
    "print(\"-----------------------------------------\")\n",
    "print(f'CPU execution time: {process_time:,} seconds')\n",
    "print(f'Inference speed: {inference_speed:.2f} messages per second')\n",
    "print(\"-----------------------------------------\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing train datasets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "847b9221b6af4bdc81989bd53d9f28e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Dataset/X-CANIDS/z/dump4.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump1.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump3.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump2.parquet is saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Processing valid datasets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "030925bddba84f1c9bc23a3afa3fdbe4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Dataset/X-CANIDS/z/dump5.parquet is saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Processing test datasets:   0%|          | 0/126 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69ab856787934402ae7f26d1c14b54a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Dataset/X-CANIDS/z/dump6-fabr-2B0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-316h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-541h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-2B0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-541h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-220h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-329h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-383h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-58Bh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-251h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-547h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-58Bh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-081h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-90.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-383h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-080h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-80.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-251h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-1000.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-557h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-556h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-18Fh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-5B0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-556h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-557h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-111h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-4F1h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-30.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-20.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-repl-0-120.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-220h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-316h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-329h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-2B0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-329h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-220h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-541h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-316h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-40.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-50.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-18Fh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-4F1h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-111h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-5B0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-100.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-18Fh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-4F1h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-111h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-557h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-556h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-5B0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-251h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-547h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-58Bh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-081h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-383h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-080h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-080h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-081h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-repl-120-240.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-547h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-555h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-50Ch.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-555h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-10.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-112h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-113h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-400.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-381h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-repl-240-360.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-200h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-545h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-47Fh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-381h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-5A0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-386h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-387h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-200.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-5A0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-044h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-549h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-162h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-593h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-549h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-52Ah.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-593h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-162h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-260h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-553h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-200h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-545h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-381h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-47Fh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-200h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-500.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-47Fh.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-545h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-112h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-113h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-50Ch.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-1500.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-113h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-112h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-2000.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-555h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-50Ch.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-300.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-553h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-162h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-260h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-52Ah.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-553h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-260h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-593h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-52Ah.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-549h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-70.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fuzz-60.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-044h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-387h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-386h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-repl-360-479.99999.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-masq-5A0h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-386h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-susp-387h.parquet is saved.\n",
      "../../Dataset/X-CANIDS/z/dump6-fabr-044h.parquet is saved.\n",
      "-----------------------------------------\n",
      "CPU execution time: 24.97049399999969 seconds\n",
      "Inference speed: 169418.43 messages per second\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T10:12:12.426661Z",
     "start_time": "2024-09-19T10:12:12.223679Z"
    }
   },
   "source": [
    "del df_itv, df_z\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": "### Move(copy) z data files to the result folder"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T10:12:12.430058Z",
     "start_time": "2024-09-19T10:12:12.427288Z"
    }
   },
   "source": [
    "if DATASET == 'X-CANIDS':\n",
    "    feature_files = {\n",
    "        'train': glob.glob(f'{DATASET_DIR}/z/dump[1-4].parquet'),\n",
    "        'valid': [f'{DATASET_DIR}/z/dump5.parquet'],\n",
    "        'test': glob.glob(f'{DATASET_DIR}/z/dump6-*.parquet'),\n",
    "    }\n",
    "elif DATASET == 'Syncan':\n",
    "    feature_files = {\n",
    "        'train': [\n",
    "            f'{DATASET_DIR}/z/z_train.parquet'\n",
    "        ],\n",
    "        'valid': [\n",
    "            f'{DATASET_DIR}/z/z_valid.parquet'\n",
    "        ],\n",
    "        'test': [\n",
    "            f'{DATASET_DIR}/z/z_normal.parquet',\n",
    "            f'{DATASET_DIR}/z/z_flooding.parquet',\n",
    "            f'{DATASET_DIR}/z/z_plateau.parquet',\n",
    "            f'{DATASET_DIR}/z/z_continuous.parquet',\n",
    "            f'{DATASET_DIR}/z/z_playback.parquet',\n",
    "            f'{DATASET_DIR}/z/z_suppress.parquet'\n",
    "        ]\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T10:13:06.380644Z",
     "start_time": "2024-09-19T10:12:12.430538Z"
    }
   },
   "source": [
    "# test results\n",
    "dt_exp = '2024-07-19_09-29-18'\n",
    "for ft_file in tqdm(feature_files['test']):\n",
    "    df = pd.read_parquet(ft_file)\n",
    "    results = df\n",
    "    if DATASET == 'Syncan':\n",
    "        attack = Path(ft_file).stem.split('_')[-1]\n",
    "        save_path = f'../../Results/{DATASET}_TIL_{dt_exp}_{attack}.parquet'\n",
    "        results.to_parquet(save_path)\n",
    "    elif DATASET == 'X-CANIDS':\n",
    "        attack = '-'.join(Path(ft_file).stem.split('-')[1:])\n",
    "        save_path = f'../../Results/{DATASET}_TIL_{dt_exp}_{attack}.parquet'\n",
    "        results.to_parquet(save_path)\n",
    "    print(f'{save_path} saved.')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9414579c25cf4dcd99e0d32ed6bf4f6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-2B0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-316h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-541h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-2B0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-541h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-220h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-329h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-383h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-58Bh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-251h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-547h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-58Bh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-081h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-90.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-383h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-080h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-80.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-251h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-1000.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-557h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-556h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-18Fh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-5B0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-556h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-557h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-111h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-4F1h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-30.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-20.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_repl-0-120.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-220h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-316h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-329h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-2B0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-329h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-220h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-541h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-316h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-40.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-50.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-18Fh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-4F1h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-111h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-5B0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-100.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-18Fh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-4F1h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-111h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-557h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-556h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-5B0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-251h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-547h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-58Bh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-081h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-383h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-080h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-080h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-081h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_repl-120-240.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-547h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-555h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-50Ch.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-555h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-10.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-112h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-113h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-400.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-381h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_repl-240-360.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-200h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-545h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-47Fh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-381h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-5A0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-386h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-387h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-200.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-5A0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-044h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-549h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-162h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-593h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-549h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-52Ah.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-593h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-162h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-260h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-553h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-200h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-545h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-381h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-47Fh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-200h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-500.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-47Fh.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-545h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-112h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-113h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-50Ch.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-1500.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-113h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-112h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-2000.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-555h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-50Ch.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-300.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-553h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-162h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-260h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-52Ah.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-553h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-260h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-593h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-52Ah.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-549h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-70.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fuzz-60.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-044h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-387h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-386h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_repl-360-479.99999.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_masq-5A0h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-386h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_susp-387h.parquet saved.\n",
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_fabr-044h.parquet saved.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T10:13:06.385513Z",
     "start_time": "2024-09-19T10:13:06.381773Z"
    }
   },
   "source": [
    "# memory usage\n",
    "objs = [df_itv_gauss, max_range, max_range]\n",
    "print(f'Model size: {asizeof.asizeof(objs)/1024:.2f} KB')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 28.77 KB\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-09-19T10:13:06.678282Z",
     "start_time": "2024-09-19T10:13:06.386345Z"
    }
   },
   "source": [
    "# validation results (for setting threshold)\n",
    "ft_file = feature_files['valid'][0]\n",
    "df = pd.read_parquet(ft_file)\n",
    "results = df\n",
    "if DATASET == 'Syncan':\n",
    "    attack = Path(ft_file).stem.split('_')[-1]\n",
    "    save_path = f'../../Results/{DATASET}_TIL_{dt_exp}_valid.parquet'\n",
    "    results.to_parquet(save_path)\n",
    "elif DATASET == 'X-CANIDS':\n",
    "    attack = '-'.join(Path(ft_file).stem.split('-')[1:])\n",
    "    save_path = f'../../Results/{DATASET}_TIL_{dt_exp}_valid.parquet'\n",
    "    results.to_parquet(save_path)\n",
    "print(f'{save_path} saved.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Results/X-CANIDS_TIL_2024-07-19_09-29-18_valid.parquet saved.\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
